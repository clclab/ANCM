{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VljrHRcPlq_z"
      },
      "source": [
        "# 2B: Representational similarity with story reading fMRI data\n",
        "\n",
        "_by Marianne de Heer Kloots, September 2022_\n",
        "\n",
        "In the first part of this week's tutorial we saw how the structure of the embeddings space changes over model layers: the embeddings become more contextualized in deeper layers. \n",
        "\n",
        "Recent work comparing language model activations to human brain measurements suggests that these deeper and more contextualized layers align better with the brain than the earlier layers (for example [Caucheteux & King, 2022](https://doi.org/10.1038/s42003-022-03036-1); [Schrimpf et al., 2021](https://doi.org/10.1073/pnas.2105646118)). These studies use trained regression models to map from model activations to brain signals, but we can also use RSA to analyze the same phenomenon. Just as we computed the correlation of RDMs from different model layers before, we can now compute the correlation between model and brain RDMs. So is it true that embeddings from later model layers form more brain-like representational spaces, compared to earlier model layers?\n",
        "\n",
        "To answer this question, we'll use fMRI scans recorded from one subject in an experiment where subjects read a chapter from the first Harry Potter book ([Wehbe et al., 2014](https://doi.org/10.1371/journal.pone.0123148)). Participants in the experiment were presented with the chapter text through Rapid Serial Visual Presentation (RSVP), meaning that the words of the chapter appeared one by one on a screen, for 500 ms each. The brain scan TR (repetition time) was 2 seconds, meaning that every 2 seconds a 3d brain volume was recorded. This means that (almost\\*) every scan records the activity of reading 4 words. We'll therefore also average the embeddings over 4 words on the model side, in order to create so-called 'TR embeddings' that give us the same temporal resolution as we have from the participant. In addition, to account for the haemodynamic response delay\\**, we take the brain scan recorded 4 seconds (2 TRs) after each text presentation as the response to that text. Finally, we restrict ourselves to voxels recorded in the left anterior temporal lobe (LATL), which is generally known to be an important area for semantics and language processing (see e.g. [Bonner & Price, 2013](https://doi.org/10.1523/JNEUROSCI.0041-13.2013), [Bemis & Pylkk√§nen, 2013](https://doi.org/10.1093/cercor/bhs170)).\n",
        "\n",
        "_____\n",
        "\\* In practice, the experiment was divided into 4 blocks, and the last scan in each block contains reading activity for only 3 words. In the code below, we provide you with all 1295 TR texts (one on each line in the `tr_texts.txt` file) and the corresponding 1295 brain responses, so the inputs and recorded activations are aligned correctly.\n",
        "\n",
        "\\** The signal recorded in fMRI studies is the so-called Blood Oxygen Level Dependent (BOLD) response, which takes about [4-6 seconds](https://www.nature.com/scitable/blog/brain-metrics/what_does_fmri_measure/) after stimulus presentation to reach its peak. We choose 4 seconds here based on earlier work where we found this to work best for this dataset ([Abnar et al., 2019](https://aclanthology.org/W19-4820/); figure 6)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Res-zZqlm6_"
      },
      "outputs": [],
      "source": [
        "!pip -q install pathlib wget transformers nilearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I3EtnjmmG6f"
      },
      "source": [
        "For this part of the tutorial, we import some helper functions from Marianne's research code for dealing with the fMRI data. If you're curious to know what is going on under the hood, you can look up any specific function in the [fmri_data_loading.py](https://github.com/clclab/ANCM/blob/main/lab2/fmri_data_loading.py) file, or run a code cell with a function name followed by `?`. Although some of these functions have different names than the ones we used before, it should be clear that we will be following the same steps overall: computing distance matrices for different layers of our model (and now also for the brain), and then calculate the correlation between them for RSA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NDDfl3PsmC_B"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "if not os.path.exists('fmri_data_loading.py'):\n",
        "  wget.download('https://raw.githubusercontent.com/clclab/ANCM/main/lab2/fmri_data_loading.py')\n",
        "tr_texts_file = 'tr_texts.txt'\n",
        "if not os.path.exists(tr_texts_file):\n",
        "  wget.download('https://raw.githubusercontent.com/clclab/ANCM/main/lab2/tr_texts.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lMfwr3obmVL_"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import nilearn.signal\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from fmri_data_loading import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWwuJiEBmRjj",
        "outputId": "a8a530c3-22b8-4b83-f092-9d79c8078cd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7f0bbc3cdf90>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name,\n",
        "            output_hidden_states=True,\n",
        "            output_attentions=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9MTS6bSnL6C"
      },
      "source": [
        "Below we download the data from subject 8 in the Wehbe et al. (2014) experiment. You can find more information on this dataset, as well as the data from other subjects, [here](http://www.cs.cmu.edu/~fmri/plosone/). In particular, a description of all the information available per subject is available [here](http://www.cs.cmu.edu/~fmri/plosone/files/description.txt) (the original data is stored in .mat files, which we convert to python dictionaries below, but they contain the same information; you can run the `load_subj_dict?` cell below to see more information about the structure of the dictionaries). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wehbenodnPd4"
      },
      "outputs": [],
      "source": [
        "load_subj_dict?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4JTv-7KunNwm"
      },
      "outputs": [],
      "source": [
        "# download data for subject 8\n",
        "subj_raw_file = 'subject_8.mat'\n",
        "if not os.path.exists(subj_raw_file):\n",
        "    url = 'http://www.cs.cmu.edu/~fmri/plosone/files/subject_8.mat'\n",
        "    wget.download(url)\n",
        "\n",
        "# load into python dictionary\n",
        "subj_dict = load_subj_dict(subj_raw_file)\n",
        "\n",
        "# preprocess fMRI signals\n",
        "subj_cleaned_file = 'subject_8_clean.npy'\n",
        "if not os.path.exists(subj_cleaned_file):\n",
        "    # preprocessing parameters\n",
        "    cleaning_params = {\n",
        "        't_r': 2,                 # TR length in seconds\n",
        "        'low_pass': None,         # low-pass filter frequency cutoff (Hz)\n",
        "        'high_pass': 0.005,       # high-pass filter frequency cutoff (Hz)\n",
        "        'standardize': 'zscore',  # standardization method\n",
        "        'detrend': True,          # whether to apply detrending\n",
        "    }\n",
        "\n",
        "    cleaned_subj_dict = copy.copy(subj_dict)\n",
        "    cleaned_subj_dict['data'] = nilearn.signal.clean(subj_dict['data'], \n",
        "                                    runs=subj_dict['time'][:,1], \n",
        "                                    **cleaning_params)\n",
        "    np.save(subj_cleaned_file, cleaned_subj_dict)\n",
        "subj_dict = np.load(subj_cleaned_file, allow_pickle=True).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFsakITwnS4z"
      },
      "source": [
        "Below we select the regions of interest (ROIs) in the left anterior temporal lobe (LATL) from which we will retrieve the brain responses and construct the brain-side RDMs. You can later define another selection of ROIs yourself, if you like (run `subj_dict['meta']['ROInumToName']` to see a list of all available ROIs in this dataset, they are based on the [AAL Single-Subject atlas](https://www.pmod.com/files/download/v36/doc/pneuro/6750.htm))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KSxgQdASnTQC"
      },
      "outputs": [],
      "source": [
        "# subregions of left-anterior temporal lobe\n",
        "LATL_ROI = ['Temporal_Sup_L', 'Temporal_Pole_Sup_L', \n",
        "            'Temporal_Mid_L', 'Temporal_Pole_Mid_L', 'Temporal_Inf_L', \n",
        "            'Fusiform_L', 'ParaHippocampal_L']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0GV1sXUnVcR"
      },
      "source": [
        "We now have the brain response scans for each of the 1295 text TRs; there are 4210 voxels in our LATL ROI selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2iBn6aHnWDy",
        "outputId": "32531caf-eae6-4b61-8a6a-c7790e1dab08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1295, 4210)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "brain_responses = get_text_response_scans(subj_dict, \n",
        "                                          delay=2,\n",
        "                                          ROI=LATL_ROI) # delay in TRs (1 TR = 2 sec)\n",
        "brain_responses['voxel_signals'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhcZXnqfnZp6"
      },
      "source": [
        "Below we load `tr_texts` (a list of texts, one for every TR containing the text presented during that TR), and we calculate the number of words presented during each TR (a list of mostly 4s and some 3s). We then split the text into sentences which we will present to our model to extract the embeddings. Note that for BERT, this means that the model will for some TRs have access to the words at the end of the sentence, which the experiment participant hadn't seen at the time the brain scan was recorded. If you'd like, you can try out different ways of providing input text to the model, for example a fixed text window for each TR excluding words presented after that TR (a way to 'make BERT causal' as discussed in the lecture)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f0swHZoKnXzz"
      },
      "outputs": [],
      "source": [
        "tr_texts = open(tr_texts_file, 'r').read().splitlines()\n",
        "words_per_tr = [len(tr.split(' ')) for tr in tr_texts]\n",
        "hp_sentences = create_context_sentences(tr_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWIqkX9zncGS"
      },
      "source": [
        "We process all sentences of the Harry Potter chapter through BERT, and extract the embeddings for each word at every layer. There are 5176 words and 13 'layers' (input embeddings + 12 model layers), which each have a 768-dimensional activation vector for every word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SNyaleHndF6",
        "outputId": "4321f964-bb96-4e94-a81b-21228ee2da7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5176, 13, 768)\n",
            "CPU times: user 4min 42s, sys: 1.84 s, total: 4min 44s\n",
            "Wall time: 4min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# this will take a few minutes\n",
        "layer_acts_bert = get_layer_activations(model, \n",
        "                      tokenizer, \n",
        "                      hp_sentences)\n",
        "layer_acts_bert = np.concatenate(layer_acts_bert)\n",
        "print(layer_acts_bert.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wxIqqwQngFb"
      },
      "source": [
        "Then we average over the words in each TR to get the 'TR embeddings':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwf8l7RKnhQj",
        "outputId": "90b80187-f02a-4a52-98a2-628af55d958a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1295, 13, 768)\n"
          ]
        }
      ],
      "source": [
        "tr_embeddings_bert = get_tr_embeddings(layer_acts_bert, words_per_tr)\n",
        "print(tr_embeddings_bert.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcoLFRMfnikD"
      },
      "source": [
        "Now we have activations vectors for each of the 1295 text TRs for each layer of the model. We also have brain responses to each of the 1295 text TRs, so we can create RDMs for both! (13 RDMs for each layer of the model, and 1 RDM for subject 8's brain responses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHhYtD04njMr",
        "outputId": "b89bd79a-9bf6-443e-be01-971410742cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1295, 1295)\n",
            "(1295, 1295)\n"
          ]
        }
      ],
      "source": [
        "RDMs_bert = [vector_distance_matrix(tr_embeddings_bert[:,layer,:],\n",
        "                                   metric=\"cosine\")\n",
        "             for layer in range(tr_embeddings_bert.shape[1])]\n",
        "\n",
        "RDM_brain = vector_distance_matrix(brain_responses['voxel_signals'],\n",
        "                                   metric=\"cosine\")\n",
        "\n",
        "print(RDMs_bert[0].shape) # one of the model RDMs\n",
        "print(RDM_brain.shape) # the brain RDM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idv84gWInmO0"
      },
      "source": [
        "We can compute the RSA score (Pearson's correlation) between each of the model layers and the brain responses now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OeEGzaHknmrb"
      },
      "outputs": [],
      "source": [
        "rsa_scores_bert = [compute_rsa_score(RDM_brain,\n",
        "                                     RDMs_bert[layer],\n",
        "                                     score=\"pearsonr\")\n",
        "                   for layer in range(len(RDMs_bert))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRnrxyUmnohb"
      },
      "source": [
        "As we see below, the correlation values themselves are quite low (they might get a bit higher if you provide the model with more context text). But we do observe the expected qualitative pattern: the higher layers with more contextualized embeddings score up to twice as high in representational similarity compared to lower layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2BZ_SMrSno_M",
        "outputId": "b0b53be3-821e-49fc-b550-30e4d67f2aab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1fnH8c+XXXrv0kE6IioixUIsqCj+xMQYa+wSo8auMbHEqIlJrClGI1hRQcWGFRXsClIUpfdeduksZZfdfX5/3Ls6LrvLDMzd2fK8X6957Z1bznnuzOw8c8+591yZGc4551y8qqQ6AOecc+WLJw7nnHMJ8cThnHMuIZ44nHPOJcQTh3POuYR44nDOOZcQTxyVjKT2kkxSehzrXijp8xKWPy3pniTG9kdJI5JVXljmUZLm7uW2bSVlSUoLn38s6dJ9iGWmpKP3dvvKQNISSYPiWK/Ez3G85bi9s8cvD5c6kpYALYGWZrYuZv43wMFABzNbkproks/M/hpBmZ8BXfdy22VAnSTGckDBtKQ7gU5mdl6yyneutPgRR9m3GDi74ImkA4FaqQtn78RzhFNRldd9L69xp0pler08cZR9I4HzY55fADwbu4Kk+pKelZQpaamk2yRVCZelSbpf0jpJi4AhRWz7hKTVklZKuqegaSZOTSR9IGmrpE8ktYsp2yRdKWk+MD+c909JyyVtkTRV0lEx698p6blwuqAp4gJJy8L4by0uCEknS5oVxrFS0o3h/KMlrYhZb4mkmyR9J2lbuO/NJb0bbvuhpIaFYtjtC0FSR0kTJK0PY3teUoNC9fxe0nfANknpBc0nkgYDfwTODJvCpks6Q9LUQnVcL+mNYva3paSxkjZIWiDpspj5OyQ1iln3kDDGquHziyXNlrRR0rg9vWeF6i14TS4K38eNki6XdFj4mm6S9J+Y9auEn8elkjLCz2n9mOW/DpetL/z+htveImlhuPyl2P2Kl6S+kr4KY1st6T+SqoXLHpH0QKH1x0q6Lub1fEXB/9ZiSVfHrHenpDGSnpO0BbgwrGtK+PleK+nBROMtF8zMH2X0ASwBBgFzge5AGrACaAcY0D5c71ngDaAu0B6YB1wSLrscmAO0ARoBH4XbpofLXwP+B9QGmgFfA78Jl10IfF5CfE8DW4GBQHXgn7Hrh/V8ENZbM5x3HtCYoJn0BmANUCNcdifwXDjdPtx+OFATOAjIBroXE8tq4KhwuiHQO5w+GlhR6DWdCDQHWgEZwDTgEKAGMAH4U6EYCl6rj4FLw+lOwPHhfjcFPgUeLlTPt+HrXjP2/Sy8r+Hz6sCG2P0DvgFOL2Z/PwX+G8Z8MJAJHBsumwBcFrPufcBj4fRQYAHB5ykduA34sqT3rFC9Ba/JY2HdJwA7gdcJPj8Fr+nPwvUvDuvbn6DZ71VgZLisB5DFj5+fB4HcmNfomvC9ah0u/x8wqqj3prj/nXD6UKB/uL/tgdnAteGyvsAqoEr4vAmwneDzUQWYCtwBVAv3YRFwYsx7uAs4LVy3JvAV8OtweR2gf6q/RyL5bkp1AP4o4c35MXHcBtwLDA7/qdPDf5r2BMkkB+gRs91vgI/D6QnA5THLTij4hwv/ObJjvyAImsU+CqcvZM+JY3TM8zpAHtAmfG6EX2YllLEROCicvpPdE0frmHW/Bs4qppxl4X7XKzT/aHZPHOfGPH8FeDTm+e+A1wvFsFviKKL+04BvCtVzcVHvZ+F9jVn+KPCXcPqA8LWpXkRdbcLXuW7MvHuBp8PpS4EJ4bSA5cDA8Pm7hD8qwudVCL4o28XznsW8Jq1i5q0Hziz0mhZ8MY8HrohZ1pXgyzad4As59vNTm+CzXPAazQaOi1neImbbn7w3xf3vFLPsWuC1mOezgePD6auAd8LpfsCyQtv+AXgq5j38tNDyT4E/A0325X+/rD+8qap8GAmcQ/BF/myhZU2AqsDSmHlLCX75QdC5vrzQsgLtwm1Xh4fxmwh+1TUrHICCM56ywsdjMYt+KNvMsgh+NbcsanlYzo1hM8nmsL764T4UZ03M9HaK76w+HTgZWKqgyWxACWWujZneUcTzPXaIh81bo8NmsS3Ac+y+H8uL2LQkzwDnSBLwa+AlM8suYr2WwAYz2xozL/Y9fwUYIKkFwa/5fOCzcFk74J8x7/cGguTSKqaseOKO9zVsye6fzYIfLT/5bJrZNoIkVKAd8FpMrLMJEmbzOOL7gaQukt6StCZ8r/7KT9+rZwiOhAn/joypv2VB/WEMfyxUf+HX6hKgCzBH0mRJpyQSa3nhiaMcMLOlBJ3kJxMc6sdaR/ArrF3MvLbAynB6NcEv1NhlBZYTHHE0MbMG4aOexZz9ExPDX82sTvi4PGbRD2VLqkPQxLEqdtOY5UcBNwO/AhqaWQNgM8EX1z4xs8lmNpQg6b0OvLSvZe7BXwn27UAzq0fwhVN4P0oaenq3ZWY2keAX91EEPxRGFl4ntApoJKluzLwf3nMz2wi8D5wZljPawp/DBO/5b2Le7wZmVtPMvowz7kStYvfPZi5BovnJZ1NSLYJmzALLgZMKxVrDzFaSmEcJmms7h+/VH/npe/UcMFTSQQRNeK/H1L+4UP11zezkmG1/8lqZ2XwzO5vgc/h3YIyk2gnGW+Z54ig/LiFoQtgWO9PM8gi+JP8iqW7Y0Xk9wT8D4bKrJbVW0Ol7S8y2qwm+YB6QVC/sjOwo6WcJxHWypCPDzsa7gYlmVtwv1roEXxqZQLqkO4B6CdRVJEnVJJ0rqb6Z7QK2EPzKjlJdgvb5zZJaATcluP1aoL3CkxhiPAv8B9hlZkVeQxO+vl8C90qqIakXwefjuZjVXiA4qeKX4XSBx4A/SDoAfjg54owEY0/EKOA6SR3CHxZ/BV40s1xgDHBKzOfnLn76nfQYwee6XRhrU0lD9yKGugSfiSxJ3YDfxi40sxXAZIJE/YqZ7QgXfQ1sVXCSQ00FJ5r0lHRYcRVJOk9SUzPLBzaFs6P+LJY6TxzlhJktNLMpxSz+HbCNoOPuc4IviifDZcOBccB0gk7gwkcs5xN0/M0iaFMfQ9CWHK8XgD8RNHkcyo+H/EUZB7xH0Hm/lKBTNdHmnOL8GlgSNkVcDpybpHKL82egN8ER09vs/rruycvh3/WSpsXMHwn05KdJoChnE7TzryI4weFPZvZhzPKxQGdgjZlNL5hpZq8R/BIeHb5WM4CTEow9EU8S7NOnBEfNOwk+r5jZTOBKgs/QaoLP34qYbf8Z7sf7krYSdJT324sYbiQ48tpK8P/wYhHrPAMcSMxRXvij7BSCkw8WExzdjyBoXi3OYGCmpKww/rNiElGFoR+PYJ1zqSapJsFZSb3NbLfTYV00JA0kSNbtzL8U98iPOJwrW34LTPakUXoUXN9yDTDCk0Z8Ks2Vjs6VdQqGmBHBqb2uFEjqDkwhaMq9KMXhlBveVOWccy4h3lTlnHMuIZWiqapJkybWvn37VIfhnHPlytSpU9eZWdPC8ytF4mjfvj1TphR3JqtzzrmiSFpa1HxvqnLOOZcQTxzOOecS4onDOedcQjxxOOecS4gnDueccwnxxOGccy4hnjicc84lxBOHc86FsnPzeGnKcrbu3JXqUMo0TxzOORd68IN53DzmO254aTo+jl/xPHE45xzw9eINPP7pIjo2rc37s9by1BdLUh1SmeWJwzlX6WVl53LDy9/SpmEt3rjqSAZ1b869787m2+Wb9rxxJeSJwzlX6f3l7Vms2LiDB351EHWqp3P/Gb1oVrcGV70wjc3bvb+jME8czrlKbcKctYz6ejm/GdiRw9o3AqBBrWr855xDWLN5JzeN8f6OwjxxOOcqrQ3bcrh5zPd0268u1x3f+SfLDmnbkFtO6ub9HUXwxOGcq5TMjFtf+57NO3J48FcHUz09bbd1Ljmyg/d3FMETh3OuUnrj21W8O2MN1x/flR4t6xW5jiTv7yiCJw7nXKWzatMObn9jBoe2a8iwgfuXuK73d+zOE4dzrlLJzzduGjOdvHzjwV8dRFoV7XEb7+/4KU8czrlKZeTEpXyxYD23DelBu8a1497O+zt+FGnikDRY0lxJCyTdUsTy6pJeDJdPktQ+nN9Y0keSsiT9p9A21SQ9LmmepDmSTo9yH5xzFcfCzCzufXc2R3dtytl92yS0rfd3/CiyxCEpDXgEOAnoAZwtqUeh1S4BNppZJ+Ah4O/h/J3A7cCNRRR9K5BhZl3Ccj+JIHznXAWTm5fP9S9+S42qafzj9F5Ie26iKsz7OwJRHnH0BRaY2SIzywFGA0MLrTMUeCacHgMcJ0lmts3MPidIIIVdDNwLYGb5ZrYumvCdcxXJfz9eyPQVm/nLaQfSrF6NvS7H+zuiTRytgOUxz1eE84pcx8xygc1A4+IKlNQgnLxb0jRJL0tqXsy6wyRNkTQlMzNzb/fBOVcBfL9iM/8aP5+hB7dkSK8W+1xeZe/vKG+d4+lAa+BLM+sNfAXcX9SKZva4mfUxsz5NmzYtzRidc2XIzl15XPfStzSpU527Tu2ZlDIre39HlIljJRDb+9Q6nFfkOpLSgfrA+hLKXA9sB14Nn78M9E5GsM65ium+cXNZkJHFfWf0on6tqkkrtzL3d0SZOCYDnSV1kFQNOAsYW2idscAF4fQvgQlWwqsfLnsTODqcdRwwK5lBO+cqji8XruOJzxdz/oB2HNU5+S0PZbm/Y1dePl8v3hBJ2emRlErQZyHpKmAckAY8aWYzJd0FTDGzscATwEhJC4ANBMkFAElLgHpANUmnASeY2Szg9+E2DwOZwEVR7YNzrvzasnMXN738HR2a1OaWk7pFVs8lR3Zg4qIN3PvubHq3a8jBbRrseaOITVq0ntten8GS9dv49OZjaFG/ZlLLV2U4vOrTp49NmTIl1WE450rRjS9P59VpK3jlt4dzSNuGkda1aXsOQ/71ORK8/bujktokloh1Wdn89Z3ZvDptJa0a1OTPpx7AoB5Fnj8UF0lTzaxP4fnlrXPcOef2aNzMNYyZuoIrj+kUedKA1Pd35OUbz01cyrH3f8yb01dxxdEd+fD6n+1T0ihJZE1VzjmXCuuysvnjq99zQMt6/O7YznveIEkK+jvueXs2T32xhIuP7FAq9c5YuZlbX5/B9OWbGLB/Y+4+7QA6NasbaZ2eOJxzFYaZ8YdXv2drdi6jzjyYauml26hSmv0dW3bu4sH35/HsV0toVLs6D595MEMPbrlXV8QnypuqnHMVxstTV/DBrLXcfGJXujSP9ld3UUrj+g4z441vV3LcA5/wzFdLOK9/O8bf8DNOO6RVqSQN8MThnKsglm/Yzl1vzqJfh0ZcfETpNBMVJcr+joWZWZz3xCSuGf0tLerX4I0rj+CuoT2pX7N0O+M9cTjnyr38fOPGl6cDcP8ZB1EljntsRCnZ13fsyMnj/nFzGfzwp3y3YjN3n9aT1644gl6tU3Pqr/dxOOfKvSe/WMykxRv4xy970aZRrVSHAySvv2PCnLXc8cZMVmzcwS8OacUfTu5O07rVkxxtYvyIwzlXrs1bu5V/jJvLoO7NOePQ1qkO5wf72t+xctMOfjNyChc/PYUaVdMYdVl/Hjzz4JQnDfDE4Zwrx3Jy87nuxW+pWz2dv51+YKl1DserQa1q/DvB/o5defn875OFDHrgEz6Zl8nvB3fjnauPYkDHYgcOL3XeVOWcK7f+PWE+M1dt4bHzDqVJndT/Ei9K7wSu75i0aD23vzGDeWuzGNS9OXee2oPWDctG01usEhOHpAHAecBRQAtgBzADeBt4zsw2Rx6hc84VYdqyjTzy0QJO792awT33S3U4JQr6O9YX29+xLiube9+ZwyvTVtCqQU2Gn9+H4yO66jsZim2qkvQucCnBIIWDCRJHD+A2oAbwhqRTSyNI55yLtSMnjxtemk6L+jX506mF70hd9gT9HQft1t+Rn288P2kpxz3wCWOnr+SKozvywfUDy3TSgJKPOH5dxG1Zs4Bp4eMBSU0ii8w554px77uzWbxuGy9c1o96NVIzoGCiCvo7fvXYV9w0ZjpXH9f5h6FC+u/fiHtO6xn5UCHJUmziMLN1ktKAD83smOLWiSwy55wrwqfzMnn2q6VcfEQHDu9Yvn67xvZ3vD9rLU3qVCvVoUKSpcQ+DjPLk5Qvqb73ZzjnUm3z9l3cPOY7OjWrw82Du6Y6nL1yyZEdWLFxBxJcO6hLqV/1nQzxnFWVBXwv6QNgW8FMM7s6sqicc64Id4ydwbqsbIaf34caVdNSHc5ekcSdpx6Q6jD2STyJ41V+vMe3c86lxLvfr+aNb1dx3aAuHNi6fqrDqdT2mDjM7JnSCMQ554qTk5vPve/OoXuLelx5TMdUh1Pp+ZXjzrky76Upy1m2YTs3D+5Kepp/baWavwPOuTJt5648/jV+Pn3aNeToLk1THY4jwcQhqYqkelEF45xzhT371RIytmZz04ldy9UpqxXZHhOHpBck1ZNUm2C4kVmSboo+NOdcZbd15y7++/FCBnZpSr/9y84gf5VdPEccPcxsC3Aa8C7QAfh1pFE55xzwxOeL2bR9FzedUD6v2aio4kkcVSVVJUgcY81sF5C8eyE651wRNmzLYcRnizmp535++m0ZE0/i+B+wBKgNfCqpHbAlyqCcc+6xTxayPSeX64/vkupQXCF7TBxm9i8za2VmJ1twF5JlQJFjVznnXDKs2byTZ75cws8PaU3n5uVj4L/KpNgLACWdH07uMLOXC+aHySM36sCcc5XXvyfMJ9+Mawd1TnUorgglXTlecJuqraURiHPOASxdv40XJy/n7L5tadOo7N39zpU8rPqfSzMQ55wDePjD+aSnid8d2ynVobhi7HGsKklNgcuA9rHrm9nF0YXlnKuM5q7ZyuvfrmTYwP1pVq9GqsNxxYhndNw3gM+AD4G8aMNxzlVmD34wlzrV0rl8oA9kWJbFczpuLTP7vZm9ZGavFDziKVzSYElzJS2QdEsRy6tLejFcPklS+3B+Y0kfScqS9J9iyh4raUY8cTjnyr7pyzcxbuZaLhu4Pw1rV0t1OK4E8SSOtySdnGjB4W1nHwFOAnoAZ0sqfFf5S4CNZtYJeAj4ezh/J3A7cGMxZf+C4AZTzrkK4v7359KodjUuPrLDnld2KRVP4riGIHnslLQ1fMRzAWBfYIGZLTKzHGA0MLTQOkOBgvt9jAGOkyQz22ZmnxMkkJ+QVAe4Hrgnjhicc+XAlwvX8dn8dVxxdEfqVI+nBd2lUjw3ctrbq29aActjnq8A+hW3jpnlStoMNAbWlVDu3cADwPa9jMs5V4aYGfePm8t+9WpwXv92qQ7HxSGuYdUlnSrp/vBxStRBlRDHwUBHM3stjnWHSZoiaUpmZmYpROec2xsT5mQwbdkmrj6uc7m9j3hlE8+w6n8jaK6aFT6ukXRvHGWvBNrEPG8dzityHUnpQH1gfQllDgD6SFoCfA50kfRxUSua2eNm1sfM+jRt6jd/ca4sys837hs3l3aNa3FGn9apDsfFKZ4jjpOB483sSTN7EhgMDIlju8lAZ0kdJFUDzgLGFlpnLHBBOP1LYEI4pEmRzOxRM2tpZu2BI4F5ZnZ0HLE458qgt75fzZw1W7n++C5U9VvClhvx9kI1ADaE03GNbxz2WVwFjAPSgCfNbKaku4ApZjYWeAIYKWlBWP5ZBduHRxX1gGqSTgNOMLNZccbrnCvjcvPyeeiDeXTbry7/16tlqsNxCYgncdwLfCPpI0DAQGC3azKKYmbvAO8UmndHzPRO4Ixitm2/h7KXAD3jicM5V/a8Mm0Fi9dtY/j5fahSxW8JW57Ec1bVqLAf4bBw1u/NbE2kUTnnKrSdu/L454fzObhNAwZ1b5bqcFyC4ukcPwLYEjYt1QNuDm/m5Jxze+WFSctYtXknN5/YFcmPNsqbeHqjHgW2SzqI4MK7hcCzkUblnKuwtmXn8shHCzi8Y2MO79Qk1eG4vRBP4sgNz3QaCjxiZo8Afksu59xeeeqLxazflsONJ3ZNdShuL8XTOb5V0h+A84CBkqoAVaMNyzlXEW3evov/fbqIQd2b07ttw1SH4/ZSPEccZwLZwCVhp3hr4L5Io3LOVUj/+3QhWdm53HBCl1SH4vZBiUcc4Qi3o8zsmIJ5ZrYM7+NwziUoY+tOnvpiCace1JLuLeqlOhy3D0o84jCzPCBfUlwX/TnnXHH++9FCcvLyuW6QH22Ud/H0cWQB30v6ANhWMNPMro4sKudchbJi43aen7SUX/VpQ/smtVMdjttH8SSOV8OHc87tlX9+OB9JXH1cp1SH4pIgnivHn9nTOs45V5wFGVm8Mm0FFx3RgRb1a6Y6HJcEe0wckjoTjFfVA6hRMN/M9o8wLudcBfHQB/OoWTWNK47umOpQXJLEczruUwRXj+cCxxCcUfVclEE55yqGGSs38/b3q7nkyA40rlM91eG4JIkncdQ0s/GAzGypmd1JfPfjcM5Vcg+8P5f6Naty6UBvoKhI4ukczw6vFp8f3l9jJVAn2rCcc+Xd5CUb+GhuJrec1I16NXywiYokniOOa4BawNXAoQRDj1xQ4hbOuUrNzLjvvbk0rVudCwa0T3U4LsniOatqMoCkfDO7KPqQnHPl3afz1/H1kg3cPfQAalZLS3U4LsniuR/HAEmzgDnh84Mk/TfyyJxz5ZKZcd+4ObRuWJMzD2ub6nBcBOJpqnoYOBFYD2Bm0wluH+ucc7t5b8YaZqzcwrWDulAtPZ6vGFfexPWumtnyQrPyIojFOVfO5eUbD3wwj07N6vDzQ1qlOhwXkXgSx3JJhwMmqaqkG4HZEcflnCuHXv9mJQsysrjh+C6kVfFbwlZU8SSOy4ErgVbAKuDg8Llzzv0gJzefhz6cx4Gt6jO4536pDsdFKJ6zqtYB55ZCLM65cuzFyctYsXEHf/n5gUh+tFGRxXNW1f6S3pSUKSlD0huS/DJQ59wPduTk8a8JC+jboREDOzdJdTguYvE0Vb0AvAS0AFoCLwOjogzKOVe+PPPVEjK3ZnPTiV39aKMSiCdx1DKzkWaWGz6eI2aUXOdc5bYuK5v/frSAn3VpymHtG6U6HFcK4hmr6l1JtwCjAQPOBN6R1AjAzDZEGJ9zroz76zuz2bErj9tP6Z7qUFwpiSdx/Cr8+5tC888iSCTe3+FcJfXVwvW8Om0lVx7TkU7N6qY6HFdK4jmrqkNpBOKcK19ycvO5/Y0ZtGlUk6uO6ZzqcFwpKraPQ9KRJW0oqZ6knskPyTlXHgz/bBELMrK469SePpBhJVPSEcfpkv4BvAdMBTIJOsU7EdwJsB1wQ+QROufKnGXrt/Ov8fM5qed+HNOtWarDcaWs2MRhZteFHeCnA2cQnI67g2C4kf+Z2eelE6JzriwxM/40dgbpVcQd/9cj1eG4FCjxdFwz22Bmw83sQjM70cxOM7M/xJs0JA2WNFfSgvDMrMLLq0t6MVw+SVL7cH5jSR9JypL0n5j1a0l6W9IcSTMl/S2x3XXO7atxM9fw0dxMrju+Cy3q10x1OC4FIhvzWFIa8AhwEtADOFtS4Z8nlwAbzawT8BDw93D+TuB24MYiir7fzLoBhwBHSDopividc7vLys7lzrGz6N6iHhce3j7V4bgUiXKw/L7AAjNbZGY5BNeBDC20zlDgmXB6DHCcJJnZtvCoZmfsyma23cw+CqdzgGlA6wj3wTkX4+EP5rF2607+8vOepKf5vTYqqyjf+VZA7H08VoTzilzHzHKBzUDjeAqX1AD4P2B8McuHSZoiaUpmZmaCoTvnCpu5ajNPfbmEs/u2pXfbhqkOx6VQPIMc1pJ0u6Th4fPOkk6JPrQSY0onGC/rX2a2qKh1zOxxM+tjZn2aNm1augE6V8Hk5xu3vT6DBjWr8vsTu6U6HJdi8RxxPAVkAwPC5yuBe+LYbiXQJuZ563BekeuEyaA+4S1q9+BxYL6ZPRzHus65fTR68nK+WbaJW4d0p36tqqkOx6VYPImjo5n9A9gFQT8DEM/wl5OBzpI6SKpGMETJ2ELrjAUuCKd/CUwwMyupUEn3ECSYa+OIwTm3j9ZlZfO3d2fTf/9GfjtYB8Q3VlWOpJoE41IhqSPBEUiJzCxX0lXAOCANeNLMZkq6C5hiZmOBJ4CRkhYAGwiSC2E9S4B6QDVJpwEnAFuAW4E5wLRw+Ob/mNmIOPfXOZeggkEM7znNb9DkAvEkjj8RXD3eRtLzwBHAhfEUbmbvAO8UmndHzPROgosLi9q2fTHF+ifXuVJSMIjhVcd0olOzOqkOx5URJSYOSVWAhsAvgP4EX9rXhLeTdc5VYDm5+dz2+vfBIIbHdkp1OK4MKTFxmFm+pJvN7CXg7VKKyTlXBgz/bBELM7fx1IWHUaOqD2LofhRP5/iHkm6U1EZSo4JH5JE551KmYBDDkw/0QQzd7uLp4zgz/HtlzDy/gZNzFZSZcUfBIIanHJDqcFwZ5Ddycs79xHsz1vDx3ExuP6UH+9WvkepwXBm0x8QhqSrwW2BgOOtjgmHVd0UYl3MuBbKyc/nzm7Po0aIeFwxol+pwXBkVT1PVo0BV4L/h81+H8y6NKijnXGo8FA5i+Oh5vX0QQ1eseBLHYWZ2UMzzCZKmRxWQcy41Zq7azFNfLOacvm05xAcxdCWI5ydFXni1OACS9gfyogvJOVfa8vONW1+bQaPa1bjZBzF0exDPEcdNwEeSFhFcANgOuCjSqJxzpWrU5GV8u3wTD515kA9i6PYonrOqxkvqDHQNZ801sz2OVeWcKx/WZWXz93fnMGD/xpx2sA9i6PYsnvtxXAnUNLPvzOw7oJakK6IPzTlXGv76djCI4d2n9fRBDF1c4unjuMzMNhU8MbONwGXRheScKy1fLlzHq9+s5PKfdfRBDF3c4kkcaYr5GSIpDagWXUjOudKQnZvHba/PoG2jWlx5jA9i6OIXT+f4e8CLkv4XPv9NOM85V44N/3QRizK38fRFPoihS0w8ieP3wDCCq8cBPgD8xknOlWPL1m/n3xMWMOTAFhzd1QcxdImJ56yqfOAx4LFwVNzWZubXcThXTsUOYnj7KT1SHY4rh+I5q+pjSfXCpDEVGC7poehDc85FoWAQwxtO6OqDGLq9EpupHv0AABkgSURBVE/neH0z20JwF8BnzawfcFy0YTnnopCVncudb86kR4t6nO+DGLq9FE/iSJfUAvgV8FbE8TjnIvTg+/PI2JrNX37e0wcxdHstnk/OXcA4YIGZTQ7HqpofbVjOuWSbsXIzT3+5mHP7+SCGbt/E0zn+MvByzPNFwOlRBuWcS678fOO214NBDG/yQQzdPvJjVecqgYJBDG8b0oP6NX0QQ7dvPHE4V8Flbg0GMTy8Y2OGHtwy1eG4CiCe03H9klLnyrG/vjObnbvyfRBDlzTxXDk+X9IrwFNmNivqgJxz+27rzl18OHstb01fzfg5GVx9bCc6NvVBDF1yxJM4DgLOAkZIqgI8CYwOr+1wzpURWdm5jJ+9lre/W83H8zLJyc2nRf0aXP6zjlzhgxi6JIrnrKqtwHCCK8Z/BrwAPCRpDHC3mS2IOEbnXDG25+QyYU4Gb3+3mglzMsjOzad5veqc268tp/RqwSFtGlKlijdPueTaY+II+ziGENwutj3wAPA8cBTwDtAlwvicc4XsyMnj47kZvPX9aibMzmDHrjya1q3OWYe1YUivlvRp58nCRSuuPg7gI+A+M/syZv4YSQOjCcs5F2vnrjw+mZfJ29+t5sPZa9mek0fj2tU4/dBWDDmwJX07NCLNk4UrJfEkjvPN7PPYGZKOMLMvzOzqiOJyrtLLzs3js3nrePv71Xwway1Z2bk0rFWVoQe34pReLejXoZEPG+JSIp7E8S+gd6F5/y5i3m4kDQb+CaQBI8zsb4WWVweeBQ4F1gNnmtkSSY2BMcBhwNNmdlXMNocCTwM1CZrKrjEzi2M/nCvzcnLz+WLBOt76bjXvz1rD1p251K9ZlSEHtmBIrxYM6NiYqp4sXIoVmzgkDQAOB5pKuj5mUT2CRFCisG/kEeB4YAUwWdLYQqf0XgJsNLNOks4C/g6cCewEbgd6ho9YjxLc83wSQeIYDLy7p3icK6t25eXz5cL1vP3dKsbNXMvmHbuoWyOdEw/YjyG9WnBExyZUS/dk4cqOko44qgF1wnXqxszfAvwyjrL7EgyMuAhA0mhgKBCbOIYCd4bTY4D/SJKZbQM+l/STcwjDUXrrmdnE8PmzwGl44nDl0IyVm3l+0lLem7GGjdt3Uad6Oif0aM6QXi04snMTqqf7tbeubCo2cZjZJ8Ankp42s6V7UXYrYHnM8xVAv+LWMbNcSZuBxsC6EspcUajMVkWtKGkYwS1vadu2baKxOxeZzdt3cd/7c3h+0jJqVU1jUI/mDDmwBQO7NPV7f7tyoaSmqofN7FqCo4Dd+hDM7NRII9tHZvY48DhAnz59vA/EpVx+vvHKtBX87d05bNyewwUD2nP9CV2oV8MHHXTlS0lNVSPDv/fvZdkrgTYxz1uH84paZ4WkdKA+QSd5SWW23kOZzpU5s1dv4fbXZzBl6UZ6t23As5f05YCW9VMdlnN7paSmqqlhB/cwMzt3L8qeDHSW1IHgy/0s4JxC64wFLgC+Iug3mVDSGVJmtlrSFkn9CTrHzyc4w8u5Mmnrzl089MF8nvlqCfVqpPOP03vxy0Nb+wV6rlwr8XRcM8uT1E5SNTPLSaTgsM/iKoK7B6YBT5rZTEl3AVPMbCzwBDBS0gJgA0FyAUDSEoIzuKpJOg04ITwj6wp+PB33Xbxj3JVBZsab363mnrdmkZmVzdl923LTCV1pWLtaqkNzbp9pT5dAhGcudSc4OthWMN/MHow2tOTp06ePTZkyJdVhuEpiQUYWd7wxgy8Xrqdnq3rcc9qBHNymQarDci5hkqaaWZ/C8+O5AHBh+KjCT0/Ldc7F2J6Ty78nLGDEZ4uoWTWNu4cewDn92vlQIK7CiWd03D+XRiDOlVdmxvuz1nLXm7NYuWkHp/duzR9O7kaTOtVTHZpzkYhndNymwM3AAUCNgvlmdmyEcTlXLixdv407x87ko7mZdNuvLi/9ZgB9OzRKdVjORSqepqrngReBU4DLCc6CyowyKOfKup278njsk4X89+OFVK0ibhvSnQsOb+/jSLlKIZ7E0djMnpB0TczV5JOjDsy5suqjuRncOXYmS9dv55ReLbhtSA/2q19jzxs6V0HEkzh2hX9XSxoCrAL8WNxVOis37eCuN2cybuZa9m9am+cv7ccRnZqkOiznSl08ieMeSfWBGwgutqsHXBdpVM6VITm5+Yz4fBH/Hr8Aw7jpxK5celQHH4TQVVrxnFX1Vji5GTgm2nCcK1u+XLiO21+fwcLMbZzQozl3/F8PWjesleqwnEupkgY5/DdQ0vAffvc/V2FlbNnJPW/PZuz0VbRtVIsnL+zDsd2apzos58qEko44/FJrVyl9v2Iz5z0xiR278rjmuM789uiOPty5czFKGuTwmdIMxLmy4PsVmzl3xETq1azKa1cczv5N66Q6JOfKnD3ej0PSmxTRZFXW78fhXKJmrAyONOrWqMqoy/rTppH3ZThXlCjvx+FcuTFj5WbOHTGJOtXTGT3Mk4ZzJSnxfhzh309KLxznSp8nDecSs8fxESSdIukbSRvCmyhtlbSlNIJzLmoFzVOeNJyLXzwXAD4M/AL4vqS78zlX3sxcFSSN2tU8aTiXiHhGZFsOzPCk4SqSmauC5qlaVdO8I9y5BMVzxHEz8I6kT4Dsgpnl6Q6AzsWatWrLD0lj9LABtG3sScO5RMSTOP4CZBHci8NvmOzKtSBpTKRm1TRGDevvScO5vRBP4mhpZj0jj8S5iM1eHSSNGlXTGD2sP+0a1051SM6VS/H0cbwj6YTII3EuQrNXb+Gc4UHSGHWZJw3n9kU8ieO3wHuSdvjpuK48mrMm6NOonh4kjfZNPGk4ty/iGVa9bmkE4lwU5qzZwjnDJ1EtrQqjh3nScC4ZShqrqpuZzZHUu6jlZjYturCc23dz12zlnOGTqJomRnnScC5pSjriuB4YBjxQxDIDjo0kIueSIEgaE6maJkYPG0AHTxrOJU1JY1UNC//6Xf9cuTJvbZA00tPEqMv6e9JwLsniGavqDEl1w+nbJL0q6ZDoQ3MucfPWbuXsxyeSViVIGn4/DeeSL56zqm43s62SjgQGAU8Aj0UblnOJmx8eaaRVEaOHedJwLirxJI688O8Q4HEzexu/gtyVMfPXbuXs4ROpoqAj3JOGc9GJJ3GslPQ/4EyCiwGrx7mdi0NevrFm885Uh1GuLcjYytnDJ6EwaXT0pOFcpOJJAL8CxgEnmtkmoBFwU6RRVRK78vL5zcipDPjbeG54abonkL2wIGMrZz0+CQlGXeZJw7nSsMfEYWbbzexVM5sfPl9tZu/HU7ikwZLmSlog6ZYilleX9GK4fJKk9jHL/hDOnyvpxJj510maKWmGpFGSasQTS1mTm5fPtaO/5cPZazmxx368OX0Vx9z/MQ9/OI/tObmpDq9cWJCRxVmPTwKCpNGpmScN50pDZE1OktKAR4CTgB7A2ZJ6FFrtEmCjmXUCHgL+Hm7bAzgLOAAYDPxXUpqkVsDVQJ9w4MW0cL1yJT/fuHnMd7z9/WpuG9Kdx359KONv+BnHdmvGwx/O59j7P+GVqSvIz/dboBQnSBoTARg9zJOGc6Upyr6KvsACM1tkZjnAaGBooXWGAs+E02OA4yQpnD/azLLNbDGwICwPgmtPakpKB2oBqyLch6QzM259fQavfrOSG0/owqVH7Q9Am0a1eOTc3oy5fADN61XnhpenM/SRL5i0aH2KIy57FmRkcfbwgqTRz5OGc6UsysTRiuDugQVWhPOKXMfMcoHNQOPitjWzlcD9wDJgNbC5uGYzScMkTZE0JTMzMwm7s+/MjLvemsWor5dx5TEduerYzrut06d9I1674ggePvNg1mVlc+bjE7l85FSWrt+WgojLlowtO3lx8jLOHj4RM2PUZf3o1MyHUnOutMVzP44yQ1JDgqORDsAm4GVJ55nZc4XXNbPHgccB+vTpUybafO5/fy5PfbGEi4/owI0ndC12vSpVxGmHtOLEA/ZjxGeLePSThYx/cC0XHt6eq47tTP2aVUsx6tTJzzdmrtrC+DlrmTAng+9WbAagXeNajDi/D52be9JwLhWiTBwrgTYxz1uH84paZ0XY9FQfWF/CtoOAxWaWCSDpVeBwYLfEUdb8e/x8HvloIef2a8vtp3QnaJErWc1qafzuuM786rA23D9uLiM+X8yYqSu47vgunNO3LelpFe+s6G3ZuXy+YB0TZmfw0dwMMrZmI8EhbRpw04ldOaZrM7q3qBvX6+eci0aUiWMy0FlSB4Iv/bOAcwqtMxa4APgK+CUwwcxM0ljgBUkPAi2BzsDXQD7QX1ItYAdwHDAlwn1IiuGfLuKBD+bxi96tuHtoz4S/9JrXq8F9ZxzEBYe35563Z3HHGzN59qul3Hpyd47u2rTcf4ku37CdCXMyGD8ng4kL15OTl0/d6ukM7NKUY7s14+iuTWlcp3qqw3TOhSJLHGaWK+kqgmtA0oAnzWympLuAKWY2lmD4kpGSFgAbCM+QCtd7CZgF5AJXmlkeMEnSGGBaOP8bwuaosmrkV0v4yzuzGdKrBf84vRdVquz9l3zPVvUZdVl/Ppi1lnvfncNFT0/mqM5NuG1ID7ruV36abXLz8pm2bFPQBDU7g/kZWQDs36Q25w9ox7Hdm3FY+0ZUrYBHVM5VBDIrE83/kerTp49NmVL6ByYvT1nOTWO+Y1D35jx6Xu+kfhHm5OYzcuJS/vnhPLKyczmrb1uuG9SFpnXL5i/zTdtz+GReJhPmZPDx3Ew279hFehXRb/9GHNutOcd2a+aj2DpXxkiaamZ9dpvviSMaY6ev4trR33BEpyaMuKAP1dPTIqln47Yc/jl+Ps9NXEqNqmlccUxHLj6iAzWqRlNfvMyMBRlZjJ+TwYTZGUxZuoF8g8a1q3FMt2Yc260ZR3ZuQr0alaOj37nyyBNHKSaO92as4coXptGnXUOevqgvNatF/yW+MDOLe9+ZzYezM2jdsCa3nNSNIQe2KLX+DzNja3Yu3yzbxITZa5kwN4PlG3YAcEDLehwbJouDWjfYp+Y651zp8cRRSonj47kZXPbsFHq2qs/IS/pRp3rpnvH8xYJ13P3WLOas2Urvtg24/ZQeHNK24V6VtSsvn43bcliXlcO6rGzWb8tmfVYOmVnB3/VZ2awr+Lsth5zcfABqVK3CkZ2acGy35hzTrSkt6tdM5i4650qJJ45SSBxfLlzHRU9NpnPzOjx/af+UXW+Rl2+Mmbqc+8bNY11WNkMPbsnNg7vRsn4NtuXksW5rkAR+SAgxSSBIEMHzjdt3FVl+tbQqNKlTjcZ1qtO4TjWaFPytXZ1OzeswYP/GKW8qc87tO08cESeOKUs2cP6TX9OmYS1GD+tPw9qpv2VJVnYuj328kOGfLSLfjCoS2eFRQWH1a1b94cu/Sd1qNK79Y1IoSBIFCaJu9fRyfwqwc27Piksc5erK8bLquxWbuOipyexXrwYjL+1bJpIGQJ3q6dx4YlfO7teWZ75cAgSd003qxCaF6jSqXY1q6X7qq3MuPp449tHs1Vv49RNf06B2VZ6/rB/N6pa9Ud5bNajJH0/unuownHMVhP/M3AcLMrI4b8QkalVL44VL+3snsHOuUvDEsZeWrt/GuSMmIonnL+1Hm0a1Uh2Sc86VCk8ce2Hlph2cM3wSObn5PH9pP/b325U65yoR7+NIUMaWnZw7fCJbdu5i1GX9y9UYUc45lwx+xJGA9VnZnDtiEplbs3nm4r70bFU/1SE551yp8yOOOG3evovznvia5Ru38/RFfem9l1djO+dceedHHHHYunMX5z/1NQszsnj8133ov3/jVIfknHMp44ljD7bn5HLJ01OYuXIz/z23NwO7NE11SM45l1KeOEqwc1cew56dypSlG/jnWYcwqEfzVIfknHMp530cxdiVl88Vz0/ji4XreOCMgxjSq0WqQ3LOuTLBE0cx0quIDk1qM6j7gfyid+tUh+Occ2WGJ45iSOL2U3qkOgznnCtzvI/DOedcQjxxOOecS4gnDueccwnxxOGccy4hnjicc84lxBOHc865hHjicM45lxBPHM455xIiM0t1DJGTlAks3cvNmwDrkhhOquoorXoqSh2lVU9FqaO06vF9Kd062pnZbiO7VorEsS8kTTGzPuW9jtKqp6LUUVr1VJQ6Sqse35eyUYc3VTnnnEuIJw7nnHMJ8cSxZ49XkDpKq56KUkdp1VNR6iitenxfykAd3sfhnHMuIX7E4ZxzLiGeOJxzziXEE0cxJA2WNFfSAkm3RFTHk5IyJM2IovywjjaSPpI0S9JMSddEVE8NSV9Lmh7W8+co6gnrSpP0jaS3Iip/iaTvJX0raUoUdYT1NJA0RtIcSbMlDUhy+V3DfSh4bJF0bTLrCOu5LnzPZ0gaJalGsusI67kmrGNmsvajqP9BSY0kfSBpfvi3YUT1nBHuS76kfT5ltpg67gs/X99Jek1Sg32tBwAz80ehB5AGLAT2B6oB04EeEdQzEOgNzIhwX1oAvcPpusC8iPZFQJ1wuiowCegf0T5dD7wAvBVR+UuAJlG9JzH1PANcGk5XAxpEWFcasIbggq5kltsKWAzUDJ+/BFwYQfw9gRlALYI7l34IdEpCubv9DwL/AG4Jp28B/h5RPd2BrsDHQJ+I6jgBSA+n/56MfTEzP+IoRl9ggZktMrMcYDQwNNmVmNmnwIZkl1uojtVmNi2c3grMJvhnT3Y9ZmZZ4dOq4SPpZ15Iag0MAUYku+zSJKk+wT/6EwBmlmNmmyKs8jhgoZnt7QgKJUkHakpKJ/hiXxVBHd2BSWa23cxygU+AX+xrocX8Dw4lSOqEf0+Loh4zm21mc/e17D3U8X74egFMBFonoy5PHEVrBSyPeb6CCL5sS5uk9sAhBEcDUZSfJulbIAP4wMyiqOdh4GYgP4KyCxjwvqSpkoZFVEcHIBN4Kmx2GyGpdkR1AZwFjEp2oWa2ErgfWAasBjab2fvJrofgaOMoSY0l1QJOBtpEUA9AczNbHU6vAZpHVE9puxh4NxkFeeKoJCTVAV4BrjWzLVHUYWZ5ZnYwwa+avpJ6JrN8SacAGWY2NZnlFuFIM+sNnARcKWlgBHWkEzQrPGpmhwDbCJpFkk5SNeBU4OUIym5I8Au9A9ASqC3pvGTXY2azCZpa3gfeA74F8pJdTxH1GhEcOZc2SbcCucDzySjPE0fRVvLTXzOtw3nlkqSqBEnjeTN7Ner6wiaXj4DBSS76COBUSUsImg+PlfRckuso+BWNmWUArxE0XSbbCmBFzFHZGIJEEoWTgGlmtjaCsgcBi80s08x2Aa8Ch0dQD2b2hJkdamYDgY0E/XVRWCupBUD4NyOiekqFpAuBU4Bzw0S4zzxxFG0y0FlSh/DX2lnA2BTHtFckiaAdfbaZPRhhPU0LztiQVBM4HpiTzDrM7A9m1trM2hO8JxPMLKm/biXVllS3YJqgczHpZ72Z2RpguaSu4azjgFnJrid0NhE0U4WWAf0l1Qo/a8cR9KMlnaRm4d+2BP0bL0RRD8H/+gXh9AXAGxHVEzlJgwmadk81s+1JKzgZPewV8UHQhjqP4OyqWyOqYxRBu/Augl+gl0RQx5EEh9rfERzefwucHEE9vYBvwnpmAHdE/P4cTQRnVRGcSTc9fMyM6r0P6zoYmBK+Zq8DDSOoozawHqgf4X78meBHwgxgJFA9ono+I0iu04HjklTmbv+DQGNgPDCf4OytRhHV8/NwOhtYC4yLoI4FBP21Bf/7jyXjdfMhR5xzziXEm6qcc84lxBOHc865hHjicM45lxBPHM455xLiicM551xCPHE4F4FwhN0me7NOPNs6l0qeOJyrZCSlpToGV7554nCOYADI8L4FT0uaJ+l5SYMkfRHel6FvuF4jSa+H9zeYKKlXOL+xpPfD+yuMIBhmvqDs88J7lXwr6X+JfHGHdU0Nyx0WzrtY0sMx61wm6aGS6pKUJekBSdOBpN73w1U+njic+1En4AGgW/g4h+DK+xuBP4br/Bn4xsx6hfOeDef/CfjczA4gGN+qLYCk7sCZwBEWDACZB5ybQEwXm9mhQB/gakmNCe558X/hGGQAFwFP7qGu2gTDkh9kZp8nUL9zu0lPdQDOlSGLzex7AEkzgfFmZpK+B9qH6xwJnA5gZhPCI416BPfW+EU4/21JG8P1jwMOBSYHQzlRk8QGzbta0s/D6TZAZzObKGkCcIqk2UBVM/te0lUl1JVHMNClc/vME4dzP8qOmc6PeZ7P3v+vCHjGzP6Q8IbS0QSjzw4ws+2SPgYKbss6guCIZw7wVBx17TSzyIchd5WDN1U5l5jPCJt/wi/2dRbc3+RTgqYtJJ0EFNynejzwy5iRXRtJahdnXfWBjWHS6Ab0L1hgwXDsbcI6C0a+3Ze6nIubH3E4l5g7CfoTvgO28+Pw238GRoVNXF8SDDeOmc2SdBvBHQWrEIxceiUQzy1c3wMuD5uj5hLc+jPWS8DBZrYxCXU5FzcfHde5ckrSW8BDZjY+1bG4ysWbqpwrZyQ1kDQP2OFJw6WCH3E455xLiB9xOOecS4gnDueccwnxxOGccy4hnjicc84lxBOHc865hPw/T70RmsMXZKsAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(rsa_scores_bert)\n",
        "plt.xlabel('model layer')\n",
        "plt.xticks(range(len(rsa_scores_bert)))\n",
        "plt.ylabel('similarity score (pearson\\'s r)')\n",
        "plt.title('Model-brain similarity over model layers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZjj2yuunrID"
      },
      "source": [
        "# ASSIGNMENT (part 1)\n",
        "At first sight, the result above seems to nicely confirm the idea that the more contextualized embeddings from middle-to-high model layers show better alignment with human brain responses. But what have we really learned about language processing? \n",
        "\n",
        "To make sure that this result really captures something about the linguistic processes involved in story reading, we would ideally compare it to some 'control' or 'baseline' condition where we would _not_ expect the effect to occur. One option would be to compare results with a different brain region that we would not expect to be as much involved in language processing. Another option could be to shuffle the RDMs before computing the RSA scores, such that we compute the correlation between model and brain RDMs for unmatched TRs (you could do this several times to create a 'null distribution' of RSA scores). You might also want to see if the result can be reproduced at the group level (comparing RSA scores across individual subjects or computing a mean RDM for several subjects), compute some kind of 'noise ceiling' based on RDM-correlation across subjects ([Nili et al., 2014](https://doi.org/10.1371/journal.pcbi.1003553)), or compare to results using a different model architecture (like GPT-2). \n",
        "\n",
        "Choose at least one of the options above, and include one (or more) plot(s) in your report comparing the result obtained above to your 'baseline' / 'control' condition or analysis extension. Then describe your approach in around 200-300 words, focussing on what your analysis teaches us about human brain activity involved in language processing, and answering the following questions:\n",
        "\n",
        "- Do your new results still confirm the idea that contextualized embeddings from middle-to-high model layers show better alignment with language processing in the human brain?\n",
        "- Why is your particular baseline / control / extension important to include in analyses comparing DNN activations and brain responses?\n",
        "- What are some limitations of this particular baseline / control / extension for your analysis (i.e. alternative explanations that it does not rule out yet)?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('3.7.6')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9865b8fc30c7210bbbe2c0b0464dbc9700000eff1f4e229588b0a8358506f7f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
